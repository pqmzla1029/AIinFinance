{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('AAPL.csv',index_col=\"Date\",parse_dates=True)\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column \"a\" of a DataFrame\n",
    "# dataset[\"Close\"] = dataset[\"Close\"].str.replace(',', '').astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"Volume\"] = dataset[\"Volume\"].str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['Close: 30 Day Mean'] = dataset['Close'].rolling(window=30).mean()\n",
    "# dataset[['Close','Close: 30 Day Mean']].plot(figsize=(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for closing prices\n",
    "training_set=dataset['Close']\n",
    "training_set=pd.DataFrame(training_set)\n",
    "\n",
    "start=1200 #1200\n",
    "end=200 #200\n",
    "\n",
    "training_set=training_set[-1*start:-1*end]\n",
    "realvalue=training_set\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "#training_set_scaled = pd.DataFrame(training_set_scaled)\n",
    "#print(training_set_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # For multiple inputs\n",
    "\n",
    "# # dataset.head()\n",
    "# training_set = dataset[['Close','Open','MACD','RSI EWMA']]\n",
    "# training_set = pd.DataFrame(training_set)\n",
    "\n",
    "# start=1200 #1200\n",
    "# end=200 #200\n",
    "\n",
    "# training_set=training_set[-1*start:-1*end]\n",
    "# realvalue=training_set\n",
    "\n",
    "# # Feature Scaling\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler(feature_range = (0, 1))\n",
    "# training_set_scaled = training_set\n",
    "# training_set_scaled[['Close','Open','RSI EWMA']] = sc.fit_transform(training_set[['Close','Open','RSI EWMA']])\n",
    "# #print(training_set_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "xdata= []\n",
    "ydata =  realvalue['Close']\n",
    "window=30\n",
    "length=training_set_scaled.shape[0]-1\n",
    "#print(training_set_scaled.head())\n",
    "#column_idx = training_set_scaled.columns.get_loc('Close')\n",
    "\n",
    "training_set_scaled = np.array(training_set_scaled)\n",
    "\n",
    "for i in range(window, length):\n",
    "    xdata.append(training_set_scaled[i-window:i,:])\n",
    "    #ydata.append(training_set_scaled[i+1, column_idx]) \n",
    "xdata, ydata = np.array(xdata), np.array(ydata)\n",
    "\n",
    "per=0.9 #0.9\n",
    "split=int(per*len(xdata))\n",
    "X_test=xdata[split:,:]\n",
    "Y_test=ydata[split+31:]\n",
    "realvalue1=realvalue[-len(Y_test):]\n",
    "\n",
    "X_train=xdata[:split,:]            \n",
    "y_train=ydata[:split]\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences =True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "872/872 [==============================] - 9s 10ms/step - loss: 14181.4918\n",
      "Epoch 2/100\n",
      "872/872 [==============================] - 5s 6ms/step - loss: 12658.7508\n",
      "Epoch 3/100\n",
      "872/872 [==============================] - 5s 6ms/step - loss: 12115.7934\n",
      "Epoch 4/100\n",
      "872/872 [==============================] - 7s 8ms/step - loss: 11763.9265\n",
      "Epoch 5/100\n",
      "872/872 [==============================] - 5s 6ms/step - loss: 11412.7504\n",
      "Epoch 6/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 11104.1439\n",
      "Epoch 7/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 10791.9833\n",
      "Epoch 8/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 10492.7661\n",
      "Epoch 9/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 10215.4515\n",
      "Epoch 10/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 9944.2741\n",
      "Epoch 11/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 9667.9535\n",
      "Epoch 12/100\n",
      "872/872 [==============================] - 6s 6ms/step - loss: 9397.3546\n",
      "Epoch 13/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 9152.8556\n",
      "Epoch 14/100\n",
      "872/872 [==============================] - 7s 8ms/step - loss: 8901.8516\n",
      "Epoch 15/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 8664.4495\n",
      "Epoch 16/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 8423.2168\n",
      "Epoch 17/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 8210.6107\n",
      "Epoch 18/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 7967.6171\n",
      "Epoch 19/100\n",
      "872/872 [==============================] - 7s 8ms/step - loss: 7750.1452\n",
      "Epoch 20/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 7519.3434\n",
      "Epoch 21/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 7327.0187\n",
      "Epoch 22/100\n",
      "872/872 [==============================] - 7s 8ms/step - loss: 7112.4162\n",
      "Epoch 23/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 6920.2078\n",
      "Epoch 24/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 6715.9794\n",
      "Epoch 25/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 6538.9679\n",
      "Epoch 26/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 6336.0894\n",
      "Epoch 27/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 6137.9027\n",
      "Epoch 28/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 5978.5316\n",
      "Epoch 29/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 5775.1907\n",
      "Epoch 30/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 5624.8547\n",
      "Epoch 31/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 5458.2769\n",
      "Epoch 32/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 5315.9765\n",
      "Epoch 33/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 5140.2620\n",
      "Epoch 34/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 4974.9583\n",
      "Epoch 35/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 4802.2991\n",
      "Epoch 36/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 4673.4198\n",
      "Epoch 37/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 4549.0679\n",
      "Epoch 38/100\n",
      "872/872 [==============================] - 7s 8ms/step - loss: 4373.6282\n",
      "Epoch 39/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 4271.8124\n",
      "Epoch 40/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 4130.1810\n",
      "Epoch 41/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 4020.0837\n",
      "Epoch 42/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 3849.6816\n",
      "Epoch 43/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 3727.0002\n",
      "Epoch 44/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 3621.5275\n",
      "Epoch 45/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 3503.6321\n",
      "Epoch 46/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 3425.9684\n",
      "Epoch 47/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 3270.8000\n",
      "Epoch 48/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 3172.6555\n",
      "Epoch 49/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 3089.4326\n",
      "Epoch 50/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 2993.8579\n",
      "Epoch 51/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 2868.5993\n",
      "Epoch 52/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 2805.6790\n",
      "Epoch 53/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 2732.7362\n",
      "Epoch 54/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 2608.6146\n",
      "Epoch 55/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 2486.5439\n",
      "Epoch 56/100\n",
      "872/872 [==============================] - 6s 7ms/step - loss: 2461.0535\n",
      "Epoch 57/100\n",
      "256/872 [=======>......................] - ETA: 4s - loss: 2341.6089"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=X_test\n",
    "xt = np.reshape(xt, (xt.shape[0], xt.shape[1], xt.shape[2]))\n",
    "yt=regressor.predict(xt)\n",
    "#yt = np.reshape(yt,(yt.shape[0], 1))\n",
    "\n",
    "\n",
    "#predicted_stock_price = regressor.predict(xt)\n",
    "predicted_stock_price = yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pd.DataFrame(predicted_stock_price)\n",
    "pp1=pp.shift(-1)\n",
    "prediction=np.where(pp<pp1,1,-1)\n",
    "\n",
    "real=pd.DataFrame(Y_test)\n",
    "real1=real.shift(-1)\n",
    "real1=np.where(real<real1,1,-1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(real1, prediction)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.array(pp)\n",
    "\n",
    "data=real\n",
    "data['pp']=pp\n",
    "\n",
    "data['ret1']=np.log(data.Close/data.Close.shift(1))# calculating the every day return\n",
    "data['ret1']=real['ret1'].shift(-1) # bringing the return to the previous day\n",
    "data['p_sig']=prediction # prediction signal\n",
    "data['v_p']=data.p_sig*real.ret1 #value prediction retun\n",
    "\n",
    "# Plot the cumulative returns for single leaf in train dataset\n",
    "data.v_p.cumsum().plot(figsize=(15,6))\n",
    "\n",
    "# Plot the cumulative returns for full tree in train dataset\n",
    "data.ret1.cumsum().plot(figsize=(15,6))\n",
    "plt.legend([\"LSTM retun\", \"market return\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(data['Close'], color = 'red', label = 'Real AAPL Stock Price')\n",
    "plt.plot(data['pp'], color = 'blue', label = 'Predicted AAPL Stock Price')\n",
    "plt.title('AAPL Stock Price Prediction')\n",
    "#for i in j:\n",
    "#    plt.axvline(x=i)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('AAPL Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
